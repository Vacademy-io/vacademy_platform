spring.application.name=media_service
server.port=8075
management.endpoints.web.base-path=/media-service
management.endpoints.web.path-mapping.health=actuator/health
springdoc.api-docs.path=/media-service/api-docs
springdoc.swagger-ui.path=/media-service/swagger-ui.html
spring.profiles.active=${environment}
spring.ai.openai.api-key=${DEEPSEEK_API_KEY}
spring.ai.openai.base-url=https://api.deepseek.com
spring.ai.openai.chat.options.model=deepseek-chat
# Keep temperature low for structured data generation
spring.ai.openai.chat.options.temperature=0.6
spring.ai.openai.chat.options.responseFormat.type=json_object
spring.ai.retry.max-attempts=3
spring.ai.retry.initial-interval=1s
spring.ai.retry.max-interval=5s
# Increase max tokens for large documents
spring.ai.openai.chat.options.maxTokens=8192
# The DeepSeek API doesn't support embeddings, so we need to disable it.
spring.ai.openai.embedding.enabled=false
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB
spring.jackson.deserialization.fail_on_unknown_properties=false



# Main setting: How long (ms) any part of your app will wait for a DB connection.
# Increase this to be longer than your DB recovery time (e.g., 4-5 minutes).
spring.datasource.hikari.connection-timeout=300000

# How long a connection can be idle before being checked/retired.
spring.datasource.hikari.idle-timeout=360000

# How long a connection can live before being replaced. Helps clean up dead connections.
spring.datasource.hikari.max-lifetime=420000

# Sentry Configuration
sentry.dsn=${SENTRY_DSN}
sentry.send-default-pii=true

# Performance Monitoring - 100% of transactions (reduce in production for cost optimization)
sentry.traces-sample-rate=1.0
# Enable performance monitoring for all integrations
sentry.enable-tracing=true
# Database query monitoring
sentry.trace-propagation-targets=localhost,127.0.0.1
# Additional performance settings
sentry.in-app-includes=vacademy.io

# ==================== AI Model Configuration ====================
# Default AI model to use when none specified
ai.default-model=google/gemini-2.5-flash

# List of allowed models that frontend can request
ai.allowed-models=google/gemini-2.5-flash,google/gemini-2.0-flash,openai/gpt-4o-mini,openai/gpt-4o,anthropic/claude-3-haiku,anthropic/claude-3-sonnet,deepseek/deepseek-chat,mistralai/mistral-large

# Fallback models to try when primary model fails
ai.fallback-models=google/gemini-2.5-flash,openai/gpt-4o-mini,deepseek/deepseek-chat

# Maximum retry attempts for AI calls
ai.max-retry-attempts=5

# Default timeout in milliseconds for AI API calls
ai.default-timeout-ms=30000

# PDF processing configuration
ai.pdf.max-tries=20
ai.pdf.delay-ms=20000

# Audio processing configuration
ai.audio.max-tries=50
ai.audio.delay-ms=20000
